{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_ml.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oskart20/MNIST_ml/blob/master/MNIST_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH6eKqx-2j9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Clean the current env\n",
        "#import os, signal\n",
        "#os.kill(os.getpid(), signal.SIGKILL)\n",
        "\n",
        "#Create input folder and download dataset\n",
        "!rm -rf input\n",
        "!mkdir -p input\n",
        "!cd input/\n",
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1DOW6s1DpGUOsTJssnbjrM6MM27KT6s4K \n",
        "\n",
        "!unzip MNIST.zip -d input/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU6Wy2Dc2yj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import some packages to use\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "#To see our directory\n",
        "import os\n",
        "import random\n",
        "import gc   #Garbage collector for cleaning deleted data from memory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7ypFn4t22_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = '/content/input/MNIST/MNIST_JPG_training'\n",
        "test_dir = '/content/input/MNIST/MNIST_JPG_testing'\n",
        "\n",
        "train_digits = []\n",
        "for j in range(10):\n",
        "  temp = ['/content/input/MNIST/MNIST_JPG_training/{}/{}'.format(j, i) for i in os.listdir(train_dir+'/{}'.format(j))]\n",
        "  train_digits.extend(temp[:5400]) #slice the dataset and use 5400 in each class\n",
        "\n",
        "test_digits = []\n",
        "for j in range(10):\n",
        "  temp = ['/content/input/MNIST/MNIST_JPG_testing/{}/{}'.format(j, i) for i in os.listdir(test_dir+'/{}'.format(j))]\n",
        "  test_digits.extend(temp[:800]) #slice the dataset and use 800 in each class\n",
        "\n",
        "# shuffle it randomly\n",
        "random.shuffle(train_digits)\n",
        "random.shuffle(test_digits)\n",
        "\n",
        "#Clear lists that are useless\n",
        "del temp\n",
        "gc.collect()   #collect garbage to save memory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sXpAeVG3e6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets declare our image dimensions\n",
        "#we are using coloured images. \n",
        "nrows = 28\n",
        "ncolumns = 28\n",
        "channels = 3\n",
        "\n",
        "#A function to read and process the images to an acceptable format for our model\n",
        "def read_and_process_image(list_of_images, training=True):\n",
        "    \"\"\"\n",
        "    Returns two arrays: \n",
        "        X is an array of resized images\n",
        "        y is an array of labels\n",
        "    \"\"\"\n",
        "    X = [] # images\n",
        "    y = [] # labels\n",
        "\n",
        "    for image in list_of_images:\n",
        "        img = cv2.imread(image, cv2.IMREAD_COLOR)\n",
        "        img = img[...,::-1]\n",
        "        X.append(img)  #Read the image\n",
        "        #get the labels\n",
        "        if training==True:\n",
        "          y.append(image[-5:-4])    \n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_1_p8ZU3iyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the train and label data\n",
        "X, y = read_and_process_image(train_digits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "438c2gGv3k1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets view some of the pics\n",
        "plt.figure(figsize=(20,10))\n",
        "columns = 5\n",
        "for i in range(columns):\n",
        "    plt.subplot(5 / columns + 1, columns, i + 1)\n",
        "    plt.imshow(X[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "des9D5XT3nTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "del train_digits\n",
        "gc.collect()\n",
        "\n",
        "#Convert list to numpy array\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "#Lets plot the labels to be sure we just have 10 classes\n",
        "sns.countplot(y)\n",
        "plt.title('Labels for 0 through 9')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cjT-Z6x3tYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Shape of train images is:\", X.shape)\n",
        "print(\"Shape of labels is:\", y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zANPiGHM4McZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets split the data into train and validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=2)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "\n",
        "print(\"Shape of train images is:\", X_train.shape)\n",
        "print(\"Shape of validation images is:\", X_val.shape)\n",
        "print(\"Shape of labels is:\", y_train.shape)\n",
        "print(\"Shape of labels is:\", y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7mTDPwo4PVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clear memory\n",
        "del X\n",
        "del y\n",
        "gc.collect()\n",
        "\n",
        "#get the length of the train and validation data\n",
        "ntrain = len(X_train)\n",
        "nval = len(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI42LITC4SPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We will use a batch size of 32. Note: batch size should be a factor of 2.***4,8,16,32,64...***\n",
        "batch_size = 32\n",
        "\n",
        "from keras.layers import *\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('th')\n",
        "\n",
        "model = models.Sequential()\n",
        "# we use relu as activation function as relu is appropriate for this task and most used in similiar cases\n",
        "activation_func = 'relu'\n",
        "\n",
        "model.add(Conv2D(64, (20, 20), activation=activation_func, padding=\"same\", data_format='channels_last', input_shape=(28, 28, 3)))\n",
        "model.add(MaxPooling2D((2, 2), padding=\"same\", data_format='channels_last'))\n",
        "model.add(Conv2D(32, (16, 16), activation=activation_func, padding=\"same\", data_format='channels_last'))\n",
        "model.add(MaxPooling2D((2, 2), padding=\"same\", data_format='channels_last'))\n",
        "model.add(Conv2D(32, (12, 12), activation=activation_func, padding=\"same\", data_format='channels_last'))\n",
        "model.add(MaxPooling2D((2, 2), padding=\"same\", data_format='channels_last'))\n",
        "model.add(Conv2D(128, (6, 6), activation=activation_func, padding=\"same\", data_format='channels_last'))\n",
        "model.add(MaxPooling2D((2, 2), padding=\"same\", data_format='channels_last'))\n",
        "model.add(Conv2D(128, (3, 3), activation=activation_func, padding=\"same\", data_format='channels_last'))\n",
        "model.add(MaxPooling2D((2, 2), padding=\"same\", data_format='channels_last'))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))  #Dropout for regularization\n",
        "model.add(Dense(2048, activation=activation_func))\n",
        "model.add(Dense(2048, activation=activation_func))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(768, activation=activation_func))\n",
        "model.add(Dense(256, activation=activation_func))\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH-OsJiM4UdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets see our model\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNvRGjOF4XS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We'll use the RMSprop optimizer with a learning rate of 0.0001\n",
        "#We'll use categorical_crossentropy loss because its a categorical classification\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMcVDZv_4Zdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets create the augmentation configuration\n",
        "#This helps prevent overfitting\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,   #Scale the image between 0 and 1\n",
        "                                    rotation_range=40,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    shear_range=0.2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=False,)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)  #We do not augment validation data. we only perform rescale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcmEtKH54bwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create the image generators\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoYyU4i64dxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The training part\n",
        "#We train for 10 or more epochs with about 1350 steps per epoch\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=ntrain // batch_size,\n",
        "                              epochs=10,\n",
        "                              validation_data=val_generator,\n",
        "                              validation_steps=nval // batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KihNb3T54fj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lets plot the train and val curve\n",
        "#get the details form the history object\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# last_acc = history.history['val_acc'][len(history.history['val_acc'])-1]\n",
        "\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bspMTeUQ9d5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now lets predict on the first 20 Images of the test set\n",
        "X_test, y_test = read_and_process_image(test_digits)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayWg994S9iQj",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "\n",
        "i = 0\n",
        "text_labels = []\n",
        "plt.figure(figsize=(50,30))\n",
        "# display 10 images from the test batch and the predicted labels with according percentage \n",
        "for batch in test_datagen.flow(X_test, batch_size=1):\n",
        "    pred = model.predict(batch)\n",
        "    pred = pred.tolist()\n",
        "    data = pred[0]\n",
        "    prediction = max(data)\n",
        "    text_labels.append('{}:{}'.format(data.index(prediction), prediction*100))\n",
        "    plt.subplot(5 / columns + 1, columns, i + 1)\n",
        "    plt.title(text_labels[i])\n",
        "    imgplot = plt.imshow(batch[0])\n",
        "    i += 1\n",
        "    if i % 10 == 0:\n",
        "        break\n",
        "plt.show()\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "acc_print = '%.2f%%' % (scores[1]*100)\n",
        "print('Accuracy: %.2f%%' % (scores[1]*100))\n",
        "print('Loss: %.2f%%' % (scores[0]))\n",
        "print('Error rate: %.2f%%' % ((1-scores[1])*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIizujSP9kbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "model.save('model_MNIST_{}_{}_Oskar-Thaeter_v1.h5'.format(activation_func, acc_print))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}